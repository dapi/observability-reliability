# SRG-010 Backup & Recovery (–†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö)

Backup & Recovery - —ç—Ç–æ –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π –¥–∞–Ω–Ω—ã—Ö, –∏—Ö —Ö—Ä–∞–Ω–µ–Ω–∏—è, –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –ø–æ—Ç–µ—Ä–∏ –¥–∞–Ω–Ω—ã—Ö, –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ –±–∏–∑–Ω–µ—Å–∞ –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ —Ö—Ä–∞–Ω–µ–Ω–∏—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.

---

## –í–∏–¥—ã —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π

### 1. Full Backup (–ü–æ–ª–Ω–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ)

**–û–ø–∏—Å–∞–Ω–∏–µ:** –ö–æ–ø–∏—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Å–∏—Å—Ç–µ–º–µ.

**–ü–ª—é—Å—ã:**
- –ü—Ä–æ—Å—Ç–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ (–æ–¥–∏–Ω —Ñ–∞–π–ª)
- –ü–æ–ª–Ω–∞—è —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
- –ë—ã—Å—Ç—Ä—ã–π restore –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤

**–ú–∏–Ω—É—Å—ã:**
- –î–æ–ª–≥–æ —Å–æ–∑–¥–∞–µ—Ç—Å—è
- –ó–∞–Ω–∏–º–∞–µ—Ç –º–Ω–æ–≥–æ –º–µ—Å—Ç–∞
- –í—ã—Å–æ–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ —Å–∏—Å—Ç–µ–º—É

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ
- –†–µ–≥—É–ª—è—Ä–Ω–æ (—Ä–∞–∑ –≤ –Ω–µ–¥–µ–ª—é/–º–µ—Å—è—Ü)
- –î–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

**–ü—Ä–∏–º–µ—Ä:**
```bash
#!/bin/bash
# full_backup.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups/full"
S3_BUCKET="s3://myapp-backups"

echo "üîí Starting full backup: $DATE"

# PostgreSQL
pg_dump -h $DB_HOST -U $DB_USER -d $DB_NAME \
  --verbose \
  --no-password \
  --clean \
  --if-exists \
  --no-owner \
  --no-privileges \
  --no-acl \
  --file $BACKUP_DIR/full_$DATE.sql

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
if pg_restore --list $BACKUP_DIR/full_$DATE.sql > /dev/null 2>&1; then
  echo "‚úÖ Backup validation passed"

  # –°–∂–∞—Ç–∏–µ
  gzip $BACKUP_DIR/full_$DATE.sql

  # –ó–∞–≥—Ä—É–∑–∫–∞ –≤ S3
  aws s3 cp $BACKUP_DIR/full_$DATE.sql.gz $S3_BUCKET/full/

  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ S3
  aws s3 ls $S3_BUCKET/full/full_$DATE.sql.gz

  echo "üéâ Full backup completed successfully"
else
  echo "‚ùå Backup validation failed"
  exit 1
fi
```

---

### 2. Incremental Backup (–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–Ω–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ)

**–û–ø–∏—Å–∞–Ω–∏–µ:** –ö–æ–ø–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –º–æ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ (full –∏–ª–∏ incremental).

**–ü–ª—é—Å—ã:**
- –ë—ã—Å—Ç—Ä–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ
- –ú–µ–Ω—å—à–µ –∑–∞–Ω–∏–º–∞–µ—Ç –º–µ—Å—Ç–∞
- –ú–µ–Ω—å—à–µ –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ —Å–∏—Å—Ç–µ–º—É

**–ú–∏–Ω—É—Å—ã:**
- –°–ª–æ–∂–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ (–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ü–µ–ø–æ—á–∫—É –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–Ω—ã—Ö –∫–æ–ø–∏–π)
- –ï—Å–ª–∏ –æ–¥–Ω–∞ –∫–æ–ø–∏—è –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞ ‚Äî –≤—Å–µ –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ –±–µ—Å–ø–æ–ª–µ–∑–Ω—ã

**–ü—Ä–∏–º–µ—Ä:**
```bash
#!/bin/bash
# incremental_backup.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups/incremental"
S3_BUCKET="s3://myapp-backups"

# –î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–ª–Ω–æ–π –∫–æ–ø–∏–∏
LAST_FULL=$(ls -t /backups/full/full_*.sql.gz | head -1 | sed 's/.*full_//' | sed 's/.sql.gz//')

echo "üîí Starting incremental backup from $LAST_FULL"

# PostgreSQL —Å WAL (Write-Ahead Logging)
# –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é –ø–æ–ª–Ω—É—é –∫–æ–ø–∏—é
gpg --basebackup -h $DB_HOST -U $DB_USER -D $BACKUP_DIR/base/

# –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤ WAL
psql -h $DB_HOST -U $DB_USER -c "SELECT pg_switch_wal();"

# –ö–æ–ø–∏—Ä—É–µ–º WAL —Ñ–∞–π–ª—ã
find /var/lib/postgresql/wal/ -newer $BACKUP_DIR/base/ -exec cp {} $BACKUP_DIR/incremental/ \;

# –°–∂–∞—Ç–∏–µ
tar -czf $BACKUP_DIR/incremental_$DATE.tar.gz $BACKUP_DIR/incremental/

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤ S3
aws s3 cp $BACKUP_DIR/incremental_$DATE.tar.gz $S3_BUCKET/incremental/

echo "üéâ Incremental backup completed"
```

---

### 3. Differential Backup (–î–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ)

**–û–ø–∏—Å–∞–Ω–∏–µ:** –ö–æ–ø–∏—Ä—É–µ—Ç –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –º–æ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–ª–Ω–æ–π –∫–æ–ø–∏–∏.

**–ü–ª—é—Å—ã:**
- –ë—ã—Å—Ç—Ä–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ (–º–µ–Ω—å—à–µ —á–µ–º full, –±–æ–ª—å—à–µ —á–µ–º incremental)
- –ë—ã—Å—Ç—Ä–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ (–Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ full + –ø–æ—Å–ª–µ–¥–Ω–∏–π differential)
- –ë–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ–µ —á–µ–º incremental

**–ú–∏–Ω—É—Å—ã:**
- –ó–∞–Ω–∏–º–∞–µ—Ç –±–æ–ª—å—à–µ –º–µ—Å—Ç–∞ —á–µ–º incremental
- –†–∞–∑–º–µ—Ä —Ä–∞—Å—Ç–µ—Ç –ø–æ –º–µ—Ä–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π

**–ü—Ä–∏–º–µ—Ä:**
```bash
#!/bin/bash
# differential_backup.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups/differential"
S3_BUCKET="s3://myapp-backups"

# –î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–ª–Ω–æ–π –∫–æ–ø–∏–∏
LAST_FULL_DATE=$(ls -t /backups/full/full_*.sql.gz | head -1 | sed 's/.*full_//' | sed 's/.sql.gz//')

echo "üîí Starting differential backup from last full ($LAST_FULL_DATE)"

# MySQL example
mysqldump -h $DB_HOST -u $DB_USER -p$DB_PASS \
  --single-transaction \
  --master-data=2 \
  --flush-logs \
  --ignore-table=mysql.innodb_index_stats \
  --ignore-table=mysql.innodb_table_stats \
  --where="updated_at >= '$LAST_FULL_DATE'" \
  $DB_NAME > $BACKUP_DIR/differential_$DATE.sql

# –°–∂–∞—Ç–∏–µ
gzip $BACKUP_DIR/differential_$DATE.sql

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤ S3
aws s3 cp $BACKUP_DIR/differential_$DATE.sql.gz $S3_BUCKET/differential/

echo "üéâ Differential backup completed"
```

---

### 4. Continuous Backup / Point-in-Time Recovery (PITR)

**–û–ø–∏—Å–∞–Ω–∏–µ:** –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∂—É—Ä–Ω–∞–ª–æ–≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π (WAL –≤ PostgreSQL, binlog –≤ MySQL).

**–ü–ª—é—Å—ã:**
- –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–æ –ª—é–±–æ–π —Ç–æ—á–∫–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏
- –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–æ—Ç–µ—Ä—è –¥–∞–Ω–Ω—ã—Ö
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å

**–ú–∏–Ω—É—Å—ã:**
- –°–ª–æ–∂–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞
- –¢—Ä–µ–±—É–µ—Ç —Ö—Ä–∞–Ω–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö –∂—É—Ä–Ω–∞–ª–æ–≤
- –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –±–∞–∑–æ–≤–æ–π –ø–æ–ª–Ω–æ–π –∫–æ–ø–∏–∏

**PostgreSQL PITR:**
```bash
# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ postgresql.conf
wal_level = replica
archive_mode = on
archive_command = 'test ! -f /var/lib/postgresql/wal/%f && cp %p /var/lib/postgresql/wal/%f'

# 2. –°–æ–∑–¥–∞–Ω–∏–µ base backup
pg_basebackup -h $DB_HOST -U $DB_USER -D /backups/base/ -P -v

# 3. –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ WAL
cd /var/lib/postgresql/wal/
find . -type f -name "*.wal" -exec gzip {} \;
aws s3 sync . s3://myapp-backups/wal/

# 4. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–æ —Ç–æ—á–∫–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏
# recovery.conf
restore_command = 'cp s3://myapp-backups/wal/%f %p'
recovery_target_time = '2024-01-15 14:30:00'
recovery_target_action = 'promote'
```

---

## –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è

### –ü—Ä–∏–º–µ—Ä —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è

```yaml
backup_schedule:
  full_backup:
    frequency: "weekly"
    day: "sunday"
    time: "02:00 AM"  # Off-peak hours
    retention: "90 days"

  differential_backup:
    frequency: "daily"
    time: "02:00 AM"
    retention: "30 days"

  incremental_backup:
    frequency: "hourly"
    retention: "7 days"

  continuous_backup:
    frequency: "real-time"
    wal_archive: "continuous"
    retention: "14 days"

  automated_backup_verification:
    frequency: "daily"
    time: "06:00 AM"
    action: "restore to test environment"
```

---

## –•—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π

### 3-2-1 Rule (–∑–æ–ª–æ—Ç–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç)

```yaml
storage_strategy:
  rule_3_2_1:
    3_copies: true  # –¢—Ä–∏ –∫–æ–ø–∏–∏ –¥–∞–Ω–Ω—ã—Ö
    2_different_media: true  # –î–≤–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–∞ –Ω–æ—Å–∏—Ç–µ–ª—è
      # 1: –û—Ä–∏–≥–∏–Ω–∞–ª (production)
      # 2: –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è (–¥–∏—Å–∫–∏/HDD)
      # 3: –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è (cloud/offline)
    1_offsite: true  # –û–¥–Ω–∞ –∫–æ–ø–∏—è –≤–Ω–µ—à–Ω–µ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è

  locations:
    primary:
      type: "local_disks"
      path: "/backups"
      retention: "7 days"
      access_speed: "fast"

    secondary:
      type: "network_attached_storage"
      path: "nas://10.0.1.100/backups"
      retention: "30 days"
      access_speed: "medium"

    tertiary:
      type: "cloud_storage"
      provider: "aws_s3"
      bucket: "myapp-backups"
      region: "us-west-2"
      storage_class: "glacier_deep_archive"  # –î–ª—è –¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ä—à–µ 90 –¥–Ω–µ–π
      retention: "7 years"  # Compliance requirements
      access_speed: "slow"
      cost: "$0.00099/GB/month"
```

---

## –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ

### –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è

#### Strategy 1: Full Restore (Full + Differential + Incremental)

```bash
#!/bin/bash
# restore_full.sh

RESTORE_DATE="2024-01-15"
RESTORE_DIR="/restore/$RESTORE_DATE"
S3_BUCKET="s3://myapp-backups"

mkdir -p $RESTORE_DIR

echo "üîÑ Restoring database to $RESTORE_DATE"

# 1. –°–∫–∞—á–∏–≤–∞–µ–º –ø–æ–ª–Ω—É—é –∫–æ–ø–∏—é
aws s3 cp $S3_BUCKET/full/full_20240114_020000.sql.gz $RESTORE_DIR/
gunzip $RESTORE_DIR/full_20240114_020000.sql.gz

# 2. –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª–Ω—É—é –∫–æ–ø–∏—é
psql -h $DB_HOST -U $DB_USER -d postgres -c "DROP DATABASE IF EXISTS myapp_restore;"
psql -h $DB_HOST -U $DB_USER -d postgres -c "CREATE DATABASE myapp_restore;"

psql -h $DB_HOST -U $DB_USER -d myapp_restore \
  < $RESTORE_DIR/full_20240114_020000.sql

# 3. –°–∫–∞—á–∏–≤–∞–µ–º –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ–ø–∏–∏
for diff in $(aws s3 ls $S3_BUCKET/differential/ --recursive | grep "20240114" | awk '{print $4}'); do
  aws s3 cp $S3_BUCKET/$diff $RESTORE_DIR/
  gunzip $RESTORE_DIR/$(basename $diff)
  psql -h $DB_HOST -U $DB_USER -d myapp_restore \
    < $RESTORE_DIR/$(basename $diff .gz)
done

# 4. –°–∫–∞—á–∏–≤–∞–µ–º –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –∫–æ–ø–∏–∏
for inc in $(aws s3 ls $S3_BUCKET/incremental/ --recursive | grep "20240115" | awk '{print $4}'); do
  aws s3 cp $S3_BUCKET/$inc $RESTORE_DIR/
  tar -xzf $RESTORE_DIR/$(basename $inc)
  psql -h $DB_HOST -U $DB_USER -d myapp_restore \
    -f $RESTORE_DIR/incremental/wal_*.sql
done

echo "‚úÖ Restore completed to myapp_restore"
```

#### Strategy 2: Point-in-Time Recovery (PITR)

```bash
#!/bin/bash
# restore_pitr.sh

TARGET_TIME="2024-01-15 14:30:00"
RESTORE_DIR="/restore/pitr"
S3_BUCKET="s3://myapp-backups"

echo "üîÑ Point-in-Time Recovery to $TARGET_TIME"

# 1. –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º PostgreSQL
systemctl stop postgresql

# 2. –°–∫–∞—á–∏–≤–∞–µ–º base backup
aws s3 cp $S3_BUCKET/base/base_20240114.tar.gz $RESTORE_DIR/
tar -xzf $RESTORE_DIR/base_20240114.tar.gz -C $RESTORE_DIR/

# 3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ recovery
cat > $RESTORE_DIR/recovery.conf <<EOF
restore_command = 'aws s3 cp $S3_BUCKET/wal/%f %p'
recovery_target_time = '$TARGET_TIME'
recovery_target_action = 'promote'
recovery_target_inclusive = false
EOF

# 4. –ó–∞–ø—É—Å–∫–∞–µ–º PostgreSQL —Å recovery
systemctl start postgresql

# 5. –°–ª–µ–¥–∏–º –∑–∞ –ª–æ–≥–∞–º–∏
while true; do
  if grep -q "database system is ready to accept connections" /var/log/postgresql/postgresql-14-main.log; then
    echo "‚úÖ Database recovered to $TARGET_TIME"
    break
  fi
  sleep 10
done
```

#### Strategy 3: Table-level Restore

```bash
#!/bin/bash
# restore_table.sh

TABLE_NAME="users"
RESTORE_DATE="2024-01-15"
RESTORE_DIR="/restore/table"
S3_BUCKET="s3://myapp-backups"

echo "üîÑ Restoring table $TABLE_NAME to $RESTORE_DATE"

# 1. –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –±–∞–∑—É –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
psql -h $DB_HOST -U $DB_USER -d postgres -c "DROP DATABASE IF EXISTS temp_restore;"
psql -h $DB_HOST -U $DB_USER -d postgres -c "CREATE DATABASE temp_restore;"

# 2. –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª–Ω—É—é –∫–æ–ø–∏—é –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –±–∞–∑—É
aws s3 cp $S3_BUCKET/full/full_20240114_020000.sql.gz $RESTORE_DIR/
gunzip $RESTORE_DIR/full_20240114_020000.sql.gz

psql -h $DB_HOST -U $DB_USER -d temp_restore \
  < $RESTORE_DIR/full_20240114_020000.sql

# 3. –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω—É–∂–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
pg_dump -h $DB_HOST -U $DB_USER -d temp_restore \
  --table=$TABLE_NAME \
  --data-only \
  > $RESTORE_DIR/table_$TABLE_NAME.sql

# 4. –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –≤ production
psql -h $DB_HOST -U $DB_USER -d myapp_production \
  < $RESTORE_DIR/table_$TABLE_NAME.sql

# 5. –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –±–∞–∑—É
psql -h $DB_HOST -U $DB_USER -d postgres -c "DROP DATABASE temp_restore;"

echo "‚úÖ Table $TABLE_NAME restored successfully"
```

---

## –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π (Backup Verification)

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞

```python
#!/usr/bin/env python3
# verify_backup.py

import subprocess
import psycopg2
import os
from datetime import datetime, timedelta

def verify_latest_backup():
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é"""

    # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∫–æ–ø–∏—é
    latest_backup = get_latest_backup()
    print(f"üîç Verifying backup: {latest_backup}")

    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å —Ñ–∞–π–ª–∞
    if not verify_file_integrity(latest_backup):
        send_alert("Backup file corrupted", severity="critical")
        return False

    print("‚úÖ File integrity check passed")

    # 2. –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤ —Ç–µ—Å—Ç–æ–≤—É—é –±–∞–∑—É
    test_db_name = "verify_backup_" + datetime.now().strftime("%Y%m%d_%H%M%S")
    create_test_database(test_db_name)

    try:
        if not restore_to_test(latest_backup, test_db_name):
            send_alert("Restore verification failed", severity="critical")
            return False

        print("‚úÖ Restore test passed")

        # 3. –ó–∞–ø—É—Å–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã
        if not run_basic_tests(test_db_name):
            send_alert("Backup data validation failed", severity="critical")
            return False

        print("‚úÖ Data validation tests passed")

        # 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å
        backup_age = get_backup_age(latest_backup)
        if backup_age > timedelta(hours=25):
            send_alert(f"Backup is too old: {backup_age}", severity="warning")

        print(f"‚úÖ Backup age: {backup_age} (good)")

        send_alert("Backup verification successful", severity="info")
        return True

    finally:
        cleanup_test_database(test_db_name)

def get_latest_backup():
    """–ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é"""
    result = subprocess.run(
        ["aws", "s3", "ls", "s3://myapp-backups/full/", "--recursive"],
        capture_output=True,
        text=True
    )

    files = result.stdout.strip().split('\n')
    latest = sorted(files, reverse=True)[0]
    return latest.split()[-1]

def verify_file_integrity(backup_path):
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å —Ñ–∞–π–ª–∞"""
    # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
    local_path = f"/tmp/{os.path.basename(backup_path)}"
    subprocess.run(["aws", "s3", "cp", f"s3://myapp-backups/{backup_path}", local_path])

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Å—É–º–º—É
    result = subprocess.run(["md5sum", local_path], capture_output=True, text=True)
    md5 = result.stdout.split()[0]

    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å —Ä–∞–Ω–µ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º–æ–π
    with open(f"{local_path}.md5", "r") as f:
        expected_md5 = f.read().strip()

    os.remove(local_path)
    return md5 == expected_md5

def restore_to_test(backup_path, test_db_name):
    """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤ —Ç–µ—Å—Ç–æ–≤—É—é –±–∞–∑—É"""
    local_path = f"/tmp/{os.path.basename(backup_path)}"

    # –°–∫–∞—á–∏–≤–∞–µ–º –∏ —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º
    subprocess.run(["aws", "s3", "cp", f"s3://myapp-backups/{backup_path}", local_path])
    subprocess.run(["gunzip", local_path])

    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
    result = subprocess.run(
        ["pg_restore", "-h", os.getenv("DB_HOST"), "-U", os.getenv("DB_USER"), "-d", test_db_name, local_path[:-3]],
        capture_output=True
    )

    os.remove(local_path[:-3])  # .dump file
    return result.returncode == 0

def run_basic_tests(db_name):
    """–ó–∞–ø—É—Å–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã –Ω–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    conn = psycopg2.connect(
        host=os.getenv("DB_HOST"),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD"),
        database=db_name
    )

    cursor = conn.cursor()

    try:
        # –¢–µ—Å—Ç 1: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        cursor.execute("SELECT 1")
        assert cursor.fetchone()[0] == 1

        # –¢–µ—Å—Ç 2: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        cursor.execute("SELECT COUNT(*) FROM users")
        user_count = cursor.fetchone()[0]
        assert user_count > 0, "No users found"

        # –¢–µ—Å—Ç 3: –ü—Ä–æ–≤–µ—Ä—è–º –∏–Ω–¥–µ–∫—Å—ã
        cursor.execute("""
            SELECT tablename, indexname
            FROM pg_indexes
            WHERE schemaname = 'public'
        """)
        indexes = cursor.fetchall()
        assert len(indexes) > 0, "No indexes found"

        # –¢–µ—Å—Ç 4: –ü—Ä–æ–≤–µ—Ä—è–µ–º foreign keys
        cursor.execute("""
            SELECT conname
            FROM pg_constraint
            WHERE contype = 'f'
        """)

        return True

    except Exception as e:
        print(f"Test failed: {e}")
        return False

    finally:
        cursor.close()
        conn.close()

def get_backup_age(backup_path):
    """–ü–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
    result = subprocess.run(
        ["aws", "s3", "ls", f"s3://myapp-backups/{backup_path}"],
        capture_output=True,
        text=True
    )

    date_str = result.stdout.split()[0]  # YYYY-MM-DD
    time_str = result.stdout.split()[1]  # HH:MM:SS

    backup_time = datetime.strptime(f"{date_str} {time_str}", "%Y-%m-%d %H:%M:%S")
    return datetime.now() - backup_time

def create_test_database(db_name):
    """–°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –±–∞–∑—É"""
    subprocess.run([
        "psql", "-h", os.getenv("DB_HOST"), "-U", os.getenv("DB_USER"), "-d", "postgres",
        "-c", f"CREATE DATABASE {db_name};"
    ], check=True)

def cleanup_test_database(db_name):
    """–û—á–∏—â–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –±–∞–∑—É"""
    subprocess.run([
        "psql", "-h", os.getenv("DB_HOST"), "-U", os.getenv("DB_USER"), "-d", "postgres",
        "-c", f"DROP DATABASE IF EXISTS {db_name};"
    ], check=True)

def send_alert(message, severity):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ–º alert"""
    webhook_url = os.getenv("SLACK_WEBHOOK")

    payload = {
        "text": f"[Backup Verification] {severity.upper()}: {message}",
        "channel": "#alerts",
        "username": "Backup Bot"
    }

    import requests
    requests.post(webhook_url, json=payload)

if __name__ == "__main__":
    verify_latest_backup()
```

---

## –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞

### Disaster Recovery Plan

```yaml
disaster_recovery:
  rto: "4 hours"  # Recovery Time Objective
  rpo: "15 minutes"  # Recovery Point Objective

  scenarios:
    hardware_failure:
      priority: high
      steps:
        1: "Activate standby database"
        2: "Redirect traffic to standby"
        3: "Restore from latest backup"
        4: "Apply WAL/binlogs for PITR"
        5: "Verify data integrity"
        6: "Promote standby to primary"

    data_corruption:
      priority: critical
      steps:
        1: "Stop all writes immediately"
        2: "Identify corruption time"
        3: "Restore to time before corruption"
        4: "Validate restored data"
        5: "Gradual traffic restoration"

    ransomware:
      priority: critical
      steps:
        1: "Isolate affected systems"
        2: "Assess damage scope"
        3: "Restore from offline backups"
        4: "Security audit and patching"
        5: "Gradual restoration"

    region_failure:
      priority: high
      steps:
        1: "Activate multi-region failover"
        2: "Restore cross-region backups"
        3: "Update DNS and routing"
        4: "Verify all services"
```

---

## –°—Ç–æ–∏–º–æ—Å—Ç—å —Ö—Ä–∞–Ω–µ–Ω–∏—è

```yaml
storage_cost_analysis:
  monthly_costs:
    local_ssd:
      size_tb: 2
      cost_per_tb: $50
      monthly: $100

    nas:
      size_tb: 10
      cost_per_tb: $20
      monthly: $200

    aws_s3_standard:
      size_tb: 50
      cost_per_tb: $23
      monthly: $1150

    aws_s3_glacier_deep:
      size_tb: 500
      cost_per_tb: $0.99
      monthly: $495

  total_monthly: $1945
  total_annually: $23340

  optimization_strategies:
    - tiered_storage: "Move old backups to cheaper storage"
    - compression: "Use zstd/bzip2 instead of gzip"
    - deduplication: "Avoid duplicate backups"
    - retention_policies: "Delete old backups automatically"
```

---

## –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è

### Backup Orchestration

```yaml
# backup-orchestration.yml
tasks:
  - name: "Full Backup - Sunday 2 AM"
    schedule: "0 2 * * 0"  # cron: every Sunday at 2 AM
    type: full
    actions:
      - notify_team: "Starting weekly full backup"
      - create_backup: {}
      - verify_backup: {}
      - upload_to_s3: {storage_class: standard}
      - update_catalog: {}
      - cleanup_local: {retention: 7 days}
      - notify_team: "Backup completed successfully"
    on_failure:
      - alert_pager: severity=high
      - retry: {attempts: 3, delay: 1h}

  - name: "Incremental Backup - Daily 2 AM"
    schedule: "0 2 * * 1-6"  # Monday-Saturday
    type: incremental
    actions:
      - create_backup: {}
      - verify_backup: {}
      - upload_to_s3: {storage_class: standard_ia}
      - cleanup_local: {retention: 3 days}

  - name: "Verify Latest Backup - Daily 6 AM"
    schedule: "0 6 * * *"  # Every day at 6 AM
    type: verification
    actions:
      - download_latest: {}
      - verify_integrity: {}
      - restore_to_test: {}
      - run_tests: {}
      - cleanup_test: {}

  - name: "Monthly Archival - 1st of month"
    schedule: "0 3 1 * *"  # 1st day of month at 3 AM
    type: archival
    actions:
      - find_old_backups: {older_than: 90 days}
      - move_to_glacier: {}
      - update_catalog: {}
```

---

## –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```bash
# .env.backups
BACKUP_STRATEGY=full_differential_incremental
FULL_BACKUP_DAY=sunday
FULL_BACKUP_TIME=02:00
DIFFERENTIAL_TIME=02:00
INCREMENTAL_INTERVAL=hourly

# Database
DB_TYPE=postgresql
DB_HOST=prod-db.example.com
DB_USER=backup_user
DB_PASSWORD=$ecret
DB_NAME=myapp_production

# Storage
LOCAL_BACKUP_PATH=/backups
S3_BUCKET=myapp-backups
S3_REGION=us-west-2
S3_STORAGE_CLASS=standard

# Retention
RETENTION_FULL_DAYS=30
RETENTION_DIFF_DAYS=14
RETENTION_INC_DAYS=7
RETENTION_WAL_DAYS=14

# Notifications
SLACK_WEBHOOK=https://hooks.slack.com/services/xxx
PAGERDUTY_INTEGRATION_KEY=xxxxx
EMAIL_ALERTS=ops-team@example.com

# Security
ENCRYPTION_KEY=base64_encoded_key
SIGNATURE_ALGORITHM=SHA256
```

---

## Best Practices ‚úÖ

### –•—Ä–∞–Ω–µ–Ω–∏–µ
- ‚úÖ 3-2-1 rule (3 –∫–æ–ø–∏–∏, 2 –Ω–æ—Å–∏—Ç–µ–ª—è, 1 –≤–Ω–µ—à–Ω–∏–π)
- ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –±—ç–∫–∞–ø—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å
- ‚úÖ –¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ process –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∫–∞–∂–¥—ã–π –º–µ—Å—è—Ü
- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ (at rest –∏ in transit)
- ‚úÖ –†–µ–≥—É–ª—è—Ä–Ω–æ —Ä–æ—Ç–∏—Ä—É–π—Ç–µ –∫–ª—é—á–∏ —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è
- ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–æ—á–Ω—ã–µ —Å—É–º–º—ã (md5/sha256)

### –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
- ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –≤—Å–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
- ‚úÖ –ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ disaster recovery –∫–∞–∂–¥—ã–π –∫–≤–∞—Ä—Ç–∞–ª
- ‚úÖ –ò–∑–º–µ—Ä—è–π—Ç–µ RTO –∏ RPO
- ‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ runbooks –≤ –∞–∫—Ç—É–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏
- ‚úÖ –ò–º–µ–π—Ç–µ clear ownership

### –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
- ‚úÖ RBAC –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –±—ç–∫–∞–ø–∞–º
- ‚úÖ Audit logs –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
- ‚úÖ MFA –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Ö—Ä–∞–Ω–∏–ª–∏—â—É
- ‚úÖ Network isolation –¥–ª—è –±—ç–∫–∞–ø-—Å–µ—Ä–≤–µ—Ä–æ–≤
- ‚úÖ Regular penetration testing

### –ü—Ä–æ—Ü–µ—Å—Å—ã
- ‚úÖ Review and test disaster recovery plan quarterly
- ‚úÖ Update runbooks after –∫–∞–∂–¥–æ–≥–æ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞
- ‚úÖ Train new team members –Ω–∞ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
- ‚úÖ Conduct blameless postmortems –¥–ª—è failures
- ‚úÖ Automate –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ

---

## –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã

### Cloud-Native Tools
- **AWS Backup**: Managed backup service
- **AWS RDS Snapshots**: Automated DB backups
- **GCP Cloud Backup**: For GCP resources
- **Azure Backup**: For Azure services

### Database-Specific
- **pg_dump / pg_basebackup**: PostgreSQL
- **mysqldump / XtraBackup**: MySQL/MariaDB
- **mongodump**: MongoDB
- **redis-cli --rdb**: Redis
- **cassandra snapshots**: Cassandra

### Enterprise Solutions
- **Veeam**: Virtual, physical, cloud
- **Commvault**: Data protection platform
- **Rubrik**: Cloud data management
- **Cohesity**: Hyperconverged backup

### Open-Source
- **Borg**: Deduplicating archiver
- **Restic**: Fast, secure backups
- **Duplicati**: Free backup software
- **Amanda**: Advanced Maryland Automatic Network Disk Archiver

---

*Backup & Recovery - –ø—Ä–∞–∫—Ç–∏–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π –¥–∞–Ω–Ω—ã—Ö –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ –±–∏–∑–Ω–µ—Å–∞*
